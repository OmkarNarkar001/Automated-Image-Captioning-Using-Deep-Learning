Hereâ€™s a sample `README.md` for your project on GitHub:

---

# Automated Image Captioning using Deep Learning Techniques

## Overview

This project focuses on automated image captioning using deep learning techniques. We employed **Long Short-Term Memory (LSTM)** and **Gated Recurrent Unit (GRU)** models to generate captions for images. The ResNet-50 model, pretrained on large image datasets, was used for feature extraction. This work was conducted as part of the **Neural Networks and Deep Learning** course under the guidance of **Professor Braun Jerome**.

## Project Details

### Dataset

- **MS COCO 2017 Dataset**: A large-scale dataset for object detection, segmentation, and captioning.
  - **train2017**: ~118,000 images with captions (used for training).
  - **val2017**: ~5,000 images with captions (used for validation).

### Approach

1. **Data Preparation**: 
   - **Images**: Resized, cropped, flipped, converted to tensors, and normalized.
   - **Captions**: Tokenized, converted to lowercase, added special tokens, and transformed into numerical indices.

2. **Encoder-Decoder Architecture**:
   - **Encoder**: Pre-trained ResNet-50 model used for feature extraction.
   - **Decoders**:
     - **LSTM**: Captures long-term dependencies in sequences.
     - **GRU**: Simpler architecture, potentially fewer parameters, and competitive performance.

3. **Training and Evaluation**:
   - **Metrics**: METEOR and BLEU scores used to evaluate caption quality.
   - **Hyperparameters**: Batch size of 256, embedding size of 256, hidden size of 512, 5 epochs, Adam optimizer, and cross-entropy loss.

### Results

- **LSTM Model**: Achieved a slightly higher METEOR score (0.2360) indicating better alignment with human judgment in content and fluency.
- **GRU Model**: Achieved a slightly higher BLEU score (0.2868) reflecting better precision in n-gram overlap.

### Future Work

- Explore advanced encoder architectures.
- Integrate attention mechanisms to improve caption quality.
