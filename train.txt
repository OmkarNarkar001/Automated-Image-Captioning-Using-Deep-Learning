import argparse
import os
import pickle
import torch
import torch.nn as nn
import torch.utils.data as data
import numpy as np
from collections import Counter, defaultdict
from tqdm import tqdm
from torchvision import transforms
from pycocotools.coco import COCO
import math
import nltk

class Vocabulary:
    def __init__(self, threshold, vocab_file="./vocab.pkl", start_token="<start>", end_token="<end>", unknown_token="<unk>", annotation_file="../cocoapi/annotations/captions_train2017.json", load_existing=False):
        self.threshold = threshold
        self.vocab_file = vocab_file
        self.start_token = start_token
        self.end_token = end_token
        self.unknown_token = unknown_token
        self.annotation_file = annotation_file
        self.load_existing = load_existing
        self.load_or_build_vocab()

    def load_or_build_vocab(self):
        if os.path.exists(self.vocab_file) and self.load_existing:
            with open(self.vocab_file, "rb") as file:
                vocab = pickle.load(file)
            self.word2idx = vocab.word2idx
            self.idx2word = vocab.idx2word
            print("Vocabulary loaded from file.")
        else:
            self.build_vocab()
            with open(self.vocab_file, "wb") as file:
                pickle.dump(self, file)

    def build_vocab(self):
        self.init_vocab()
        self.add_word(self.start_token)
        self.add_word(self.end_token)
        self.add_word(self.unknown_token)
        self.add_captions()

    def init_vocab(self):
        self.word2idx = {}
        self.idx2word = {}
        self.index = 0

    def add_word(self, word):
        if word not in self.word2idx:
            self.word2idx[word] = self.index
            self.idx2word[self.index] = word
            self.index += 1

    def add_captions(self):
        coco = COCO(self.annotation_file)
        counter = Counter()
        ids = coco.anns.keys()
        for i, idx in enumerate(ids):
            caption = str(coco.anns[idx]["caption"])
            tokens = nltk.tokenize.word_tokenize(caption.lower())
            counter.update(tokens)

            if i % 100000 == 0:
                print(f"Tokenizing captions: [{i}/{len(ids)}]")

        words = [word for word, cnt in counter.items() if cnt >= self.threshold]
        for word in words:
            self.add_word(word)

    def __call__(self, word):
        return self.word2idx.get(word, self.word2idx[self.unknown_token])

    def __len__(self):
        return len(self.word2idx)

def parse_args():
    parser = argparse.ArgumentParser(description='Train image captioning model')
    parser.add_argument('--model', type=str, choices=['LSTM', 'GRU'], required=True, help='Select the model to train: LSTM or GRU')
    parser.add_argument('--batch_size', type=int, default=256)
    parser.add_argument('--embed_size', type=int, default=256)
    parser.add_argument('--hidden_size', type=int, default=512)
    parser.add_argument('--num_epochs', type=int, default=3)
    parser.add_argument('--save_every', type=int, default=1)
    parser.add_argument('--print_every', type=int, default=20)
    parser.add_argument('--log_file', type=str, default='training_log.txt')
    parser.add_argument('--cocoapi_dir', type=str, default=r'C:\Users\harsh\Documents')
    parser.add_argument('--vocab_threshold', type=int, default=5)
    parser.add_argument('--vocab_file', type=str, default='./vocab.pkl')
    parser.add_argument('--annotations_file', type=str, default='../cocoapi/annotations/captions_train2017.json')
    parser.add_argument('--vocab_from_file', type=bool, default=True)
    args = parser.parse_args()
    return args

def get_train_loader(transform, batch_size, vocab_threshold, vocab_file, start_word, end_word, unk_word, vocab_from_file, num_workers, cocoapi_loc):
    vocab = Vocabulary(vocab_threshold, vocab_file, start_word, end_word, unk_word, annotations_file=os.path.join(cocoapi_loc, 'annotations/captions_train2017.json'), load_existing=vocab_from_file)
    img_folder = os.path.join(cocoapi_loc, "images/train2017/")
    annotations_file = os.path.join(cocoapi_loc, "annotations/captions_train2017.json")
    
    dataset = CoCoDataset(
        transform=transform,
        mode='train',
        batch_size=batch_size,
        vocab_threshold=vocab_threshold,
        vocab_file=vocab_file,
        start_word=start_word,
        end_word=end_word,
        unk_word=unk_word,
        annotations_file=annotations_file,
        vocab_from_file=vocab_from_file,
        img_folder=img_folder,
    )
    indices = dataset.get_train_indices()
    initial_sampler = data.sampler.SubsetRandomSampler(indices=indices)
    data_loader = data.DataLoader(
        dataset=dataset,
        num_workers=num_workers,
        batch_sampler=data.sampler.BatchSampler(
            sampler=initial_sampler, batch_size=dataset.batch_size, drop_last=False
        ),
    )
    return data_loader, vocab

def get_model(model_type, embed_size, hidden_size, vocab_size):
    if model_type == 'LSTM':
        from model_LSTM import EncoderCNN, DecoderRNN
    elif model_type == 'GRU':
        from model_GRU import EncoderCNN, DecoderRNN
    encoder = EncoderCNN(embed_size)
    decoder = DecoderRNN(embed_size, hidden_size, vocab_size)
    return encoder, decoder

def validate_model(encoder, decoder, criterion, val_loader, device):
    encoder.eval()
    decoder.eval()
    total_val_loss = 0
    with torch.no_grad():
        for images, captions in val_loader:
            images = images.to(device)
            captions = captions.to(device)
            features = encoder(images)
            outputs = decoder(features, captions)
            loss = criterion(outputs.view(-1, vocab_size), captions.view(-1))
            total_val_loss += loss.item()
    avg_val_loss = total_val_loss / len(val_loader)
    encoder.train()
    decoder.train()
    return avg_val_loss

def load_checkpoint(checkpoint_path, encoder, decoder, optimizer):
    checkpoint = torch.load(checkpoint_path)
    encoder.load_state_dict(checkpoint['encoder_state_dict'])
    decoder.load_state_dict(checkpoint['decoder_state_dict'])
    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
    return checkpoint['epoch']

def main():
    args = parse_args()
    
    transform_train = transforms.Compose([
        transforms.Resize(256),
        transforms.RandomCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),
    ])
    
    data_loader, vocab = get_train_loader(
        transform=transform_train,
        batch_size=args.batch_size,
        vocab_threshold=args.vocab_threshold,
        vocab_file=args.vocab_file,
        start_word="<start>",
        end_word="<end>",
        unk_word="<unk>",
        vocab_from_file=args.vocab_from_file,
        num_workers=0,
        cocoapi_loc=args.cocoapi_dir,
    )
    
    vocab_size = len(vocab)
    encoder, decoder = get_model(args.model, args.embed_size, args.hidden_size, vocab_size)
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    encoder.to(device)
    decoder.to(device)
    
    criterion = nn.CrossEntropyLoss().to(device)
    params = list(decoder.parameters()) + list(encoder.embed.parameters())
    optimizer = torch.optim.Adam(params, lr=0.001)
    
    total_step = math.ceil(len(data_loader.dataset) / data_loader.batch_sampler.batch_size)
    
    checkpoint_path = os.path.join("models", args.model, f"{args.model}_checkpoint-1.pkl")
    if os.path.exists(checkpoint_path):
        start_epoch = load_checkpoint(checkpoint_path, encoder, decoder, optimizer) + 1
    else:
        start_epoch = 1
    
    encoder.train()
    decoder.train()
    
    log_file_path = os.path.join("logs", args.log_file)
    os.makedirs(os.path.dirname(log_file_path), exist_ok=True)
    
    with open(log_file_path, "a") as log_file:
        for epoch in range(start_epoch, args.num_epochs + 1):
            total_loss = 0
            for i_step in range(1, total_step + 1):
                indices = data_loader.dataset.get_train_indices()
                new_sampler = data.sampler.SubsetRandomSampler(indices=indices)
                data_loader.batch_sampler.sampler = new_sampler
                
                images, captions = next(iter(data_loader))
                images = images.to(device)
                captions = captions.to(device)
                
                decoder.zero_grad()
                encoder.zero_grad()
                
                features = encoder(images)
                outputs = decoder(features, captions)
                loss = criterion(outputs.view(-1, vocab_size), captions.view(-1))
                loss.backward()
                optimizer.step()
                
                total_loss += loss.item()
                
                if i_step % args.print_every == 0:
                    print(f"Epoch [{epoch}/{args.num_epochs}], Step [{i_step}/{total_step}], Loss: {loss.item():.4f}, Perplexity: {np.exp(loss.item()):.4f}")
            
            avg_train_loss = total_loss / total_step
            val_loader = get_train_loader(transform=transform_train, batch_size=args.batch_size, vocab_threshold=5, vocab_from_file=True, cocoapi_loc=args.cocoapi_dir)[0]  # Validation loader
            val_loss = validate_model(encoder, decoder, criterion, val_loader, device)
            
            log_entry = (f"Epoch [{epoch}/{args.num_epochs}], "
                         f"Train Loss: {avg_train_loss:.4f}, Train Perplexity: {np.exp(avg_train_loss):.4f}, "
                         f"Validation Loss: {val_loss:.4f}, Validation Perplexity: {np.exp(val_loss):.4f}")
            
            print(log_entry)
            log_file.write(log_entry + "\n")
            log_file.flush()
            
            if epoch % args.save_every == 0:
                torch.save({
                    'decoder_state_dict': decoder.state_dict(),
                    'encoder_state_dict': encoder.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'epoch': epoch
                }, os.path.join("models", args.model, f"{args.model}_checkpoint-{epoch}.pkl"))

if __name__ == "__main__":
    main()
